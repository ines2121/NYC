# ðŸ—½ NYC Yellow Taxi â€“ Pipeline ETL local avec PySpark + PostgreSQL

Ce projet met en place un pipeline de traitement de donnÃ©es local pour les trajets de taxis jaunes Ã  New York, avec intÃ©gration des donnÃ©es mÃ©tÃ©o.

---

## ðŸ“¦ Objectif actuel

- TÃ©lÃ©chargement des fichiers `.parquet` Yellow Taxi depuis le site NYC Open Data
- Nettoyage, enrichissement et jointure avec les donnÃ©es mÃ©tÃ©o (CSV)
- Export des donnÃ©es finales (par mois) en `.csv` et `.parquet`
- Chargement des fichiers nettoyÃ©s dans une base PostgreSQL locale
- Organisation du projet en scripts Python et Jupyter Notebook
- Gestion versionnÃ©e du projet sur GitHub (en excluant les fichiers >100 Mo)

---

## ðŸ”§ Technologies utilisÃ©es

- **Python 3.12**
- **PySpark 3.5**
- **PostgreSQL 14 (Docker)**
- **pgAdmin (Docker)**
- **Pandas / SQLAlchemy / psycopg2**
- **Jupyter Notebook (via Docker)**
- **Git + GitHub**

---

## ðŸ“‚ Structure du projet

```bash
nyc-etl-pipeline/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ etl_pipeline.ipynb          # Notebook PySpark pour l'ETL complet
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ nyc_yellow_taxi_parquet/    # Fichiers bruts parquet
â”‚   â”œâ”€â”€ nyc_weather_data/           # Fichier mÃ©tÃ©o CSV
â”‚   â””â”€â”€ final/                      # Fichiers transformÃ©s (.csv/.parquet)
â”œâ”€â”€ script-load-data/
â”‚   â””â”€â”€ load_csv_to_postgres.py     # Script pour charger un CSV dans PostgreSQL
â”œâ”€â”€ spark-3.5.3-bin-hadoop3.tgz     # Archive Spark (ignorÃ©e par Git)
â”œâ”€â”€ docker-compose.yml              # PostgreSQL + pgAdmin
â”œâ”€â”€ Dockerfile                      # Spark + Jupyter
â”œâ”€â”€ .env                            # Connexion Ã  PostgreSQL
â”œâ”€â”€ .gitignore                      # Fichiers Ã  exclure du versionnement
â””â”€â”€ README.md
```

## ðŸ§© Ã€ venir (prochaines Ã©tapes)

- [ ] Automatiser lâ€™ingestion mois par mois
- [ ] Pipeline complet avec **PostgreSQL**
- [ ] EntraÃ®nement du modÃ¨le de Machine Learning dans **Google Colab** ou avec **Spark MLlib**
- [ ] DÃ©ploiement du modÃ¨le via **Flask** ou **Streamlit** (sur le **cloud GCP**)
